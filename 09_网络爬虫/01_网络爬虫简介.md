1. 什么是网络爬虫
是一个软件机器人，是可控的，可以从互联网上抓住我们所需的资源，爬虫是搜索引擎后台的一个子系统，数据入口之一

2. 爬虫能做什么
搜索引擎的基础应用
抓取大数据的一种手段
网页下载器
网店秒杀

3. 关于项目

业务设计流程：
设计处理流程
1. 得到爬虫种子（url）
2. 根据爬取种子下载资源（页面）
3. 解析页面，提取更多的url
4. 对页面 做持久化操作
5. 根据提取的url再进行下载操作
6. 重复第二步到第五步

系统级设计：
互联网-》黑盒子-》数据库

黑盒子的输入是系统启动的时候命令行输入或者是配置文件输入

下载器下载url中的页面，需要一个解析器需要解析页面的数据，需要一个持久化器将原始页面进行持久化处理 、

配置文件就是一个参数的集合

配置文件解析模块
配置文件以文件形式保存程序运行时必要的参数，减少输入时的繁琐过程
文件类型是文本文件，内容一般以键值的形式出现
```conf
key = value

注释规则：注释字符串前以#标记

```
配置项设置                           字段
并发任务数                           job_num
url种子                             seed
抓取深度                             deeps
模块存放路径（唯一）                   log_level
输出日志的等级                        Module_path
模块名称（模块文件，可以多个）           Module_name
允许抓取的资源类型（多个，文件后缀）      file_type

模块详细设计：
配置文件解析模块
1. 读取配置文件 
2. 得到配置文件选项的值（键值）
3. 初始化

```C++
#include <stdio.h>
#include <list>
#include <string>
using namespace std;

class ConfigParse
{
public:
	
	int loader(char * conf_pathname);
	
	// for single
	ConfigParse* instance();
	// operator
	int getJobNum();
	char getUrlSeed();
	int getDeep();
	int getLoglevel();
	char * getModulePath();
	list<string> getModules();
	list<string> getFiletypes();

private: // for single
	ConfigParse();
	static ConfigParse  _self();
private:
	int job_num;
	char * seed;
	int deeps;
	int log_levels;
	char *Module_name;
	list<string> Module_name;
	list<string> file_type;
};
```
技术点：
1. 分行读取：fgets
2. 分隔字符串
3. 消除注释
4. 消除空格