1. 什么是网络爬虫
是一个软件机器人，是可控的，可以从互联网上抓住我们所需的资源，爬虫是搜索引擎后台的一个子系统，数据入口之一

2. 爬虫能做什么
搜索引擎的基础应用
抓取大数据的一种手段
网页下载器
网店秒杀

3. 关于项目

业务设计流程：
设计处理流程
1. 得到爬虫种子（url）
2. 根据爬取种子下载资源（页面）
3. 解析页面，提取更多的url
4. 对页面 做持久化操作
5. 根据提取的url再进行下载操作
6. 重复第二步到第五步

系统级设计：
互联网-》黑盒子-》数据库

黑盒子的输入是系统启动的时候命令行输入或者是配置文件输入

下载器下载url中的页面，需要一个解析器需要解析页面的数据，需要一个持久化器将原始页面进行持久化处理 、

配置文件就是一个参数的集合

配置文件解析模块
配置文件以文件形式保存程序运行时必要的参数，减少输入时的繁琐过程
文件类型是文本文件，内容一般以键值的形式出现
```conf
key = value

注释规则：注释字符串前以#标记

```
配置项设置                           字段
并发任务数                           job_num
url种子                             seed
抓取深度                             deeps
模块存放路径（唯一）                   log_level
输出日志的等级                        Module_path
模块名称（模块文件，可以多个）           Module_name
允许抓取的资源类型（多个，文件后缀）      file_type

模块详细设计：
配置文件解析模块
1. 读取配置文件 
2. 得到配置文件选项的值（键值）
3. 初始化

```C++
#include <stdio.h>
#include <list>
#include <string>
using namespace std;

class ConfigParse
{
public:
	
	int loader(char * conf_pathname);
	
	// for single
	ConfigParse* instance();
	// operator
	int getJobNum();
	char getUrlSeed();
	int getDeep();
	int getLoglevel();
	char * getModulePath();
	list<string> getModules();
	list<string> getFiletypes();

private: // for single
	ConfigParse();
	static ConfigParse  _self();
private:
	int job_num;
	char * seed;
	int deeps;
	int log_levels;
	char *Module_name;
	list<string> Module_name;
	list<string> file_type;
};
```
技术点：
1. 分行读取：fgets
2. 分隔字符串
3. 消除注释
4. 消除空格

# url 维护模块
url分成几部分
* IP或者域名
* 单纯的路径或者文件的名称
url格式：http://192.168.40.150:8080/docs/linuxdev.html
结构：域名或IP地址，路径，文件名
DNS解析就是把域名解析成ip地址

设计url的数据结构
项目                        字段名称
完整的url                   url
域名                        protocal
资源路径                    path
文件名                      filename
当前url处理状态（0-1--1）    state
当前url深度                 deep
当前资源类型                 filetype

http协议请求页面时候的流程：
1. 输入网址
2. 向DNS发送解析请求
3. DNS返回我们一个对应的IP地址
4. 通过IP地址向资源所在的主机发送请求
5. 资源错存在，主机返回状态200状态，同时thttp数据部分会吧数据部分连起来
6. 本地http客户端（一般是浏览器）接收数据
7. 得到资源

页面抓去流程
1. 得到url
2. url进入抓取队列等待抓取
3. 从队里中得到一个url，然后把url分配给一个下载实例
4. 得到下载器的处理状态（url处理状态需要被改写，得到当前url深度，得到当前资源类型，假如下载成功）
5. 得到当前页面中存在的下一级url列表


url维护操作模块(对外接口)：
1. 添加新的URL
2. 新URL进入抓去队列
3. 从抓取队列中移除一个URL
4. 修改URL库中的某一个URl的值
5. 添加新的URL的列表

日志工具
为什么需要日志工具
1. 方便调试
2. 方便代码维护

日志输出信息设计
1. 日志信息等级 + 日期时间 + 调试信息

日志输出等级设计（5个等级）
* 0：调试【debug】：仅仅用于调试
* 1：普通信息【info】:可以让使用者了解的一些信息
* 2：警告信息【warn】:意味着程序中出现了错误，但是并不严重
* 3：错误信息【error】:意味着程序中发生了严重错误，根据实际情况可选择使程序继续运行或使程序终止
* 4：程序崩溃【crash】：程序无法继续运行了

日志调用接口设计：
SPIDER_LOG(日志等级标记，日志输出信息);
注意，配置文件中的日志输出登记字段和接口中的日志等级标记不是一个概念
日志等级标记，纯粹是一个标记，体现在输出的日志字符串中
配置文件中的日志输出登记字段用来控制那些日志被输出

日志实现流程

接口内部的处理流程：
1. 得到控制日志输出等级的标记，用来控制当前日志是否需要输出
2. 得到调用日志接口的时间
3. 得到日志输出信息并进行日志字符串的拼接
4. 吧日志信息输出到指定输出设备

任务调度模块
1. 可以控制程序按照普通程序模式还是按照守护进程模式进行
2. 可以通过参数提供帮助
3. 提供一个运行框架，可以支持多任务管理
4. 包含程序的主流程

尽可能把可拆分的功能封装成独立函数进行调用


定义主程序框架的处理流程:
1. 程序运行时先处理命令行参数，根据参数跳转到响应分支或调用响应的函数
2. 检测是否按照守护进程模式运行（控制选项从命令行参数中得到）
3. 初始化环境
   1. 读取配置文件，提取配置文件中的参数
   2. 根据守护进程模式的标记将当前进程转变为守护进程
   3. 载入程序模块的动态库

4. 开始程序的主处理流程
   1. 监测种子是否存在，把种子交给URL管理器
   2. 分析种子, 得到种子url的IP地址（DNS解析）
   3. 根据种子URL得到第一个页面
   4. 对页面进行处理（复杂流程，由其他模块实现细节）
   5. 从url管理器中取出一个URL
   6. 启动一个处理任务(先检测是否达到最大任务数量，功能封装在一个独立的函数中)
   7. 监控任务处理数量，如果任务维护池中有空闲任务，那么重复5步骤
   8. 回收资源，准备结束程序

继续分解复杂步骤
1. 对页面进行处理：
   1. 对页面进行解析，提取内部的下级URL
   2. 生成URL列表，把URL列表传给URL管理器
   3. 对页面进行持久化操作

2. 处理任务
   1. 从URL管理器得到一个未处理的URL
   2. 通过调用epoll框架产生一个新任务
   3. 调用页面处理过程（复杂步骤1）
   4. 释放过程中产生的临时资源（socket句柄，文件操作句柄，临时申请的内存等）

其他辅助功能：
1. 输出其他帮助信息
2. 

Linux下设计的并发网络程序，有典型的额Apache模型，TPC模型，以及select模型和poll模型

# 插件框架设计
1. 升级和扩充功能
2. 维护方便
3. 动态修改

模块管理器设计：
1. 动态载入so.文件
2. 维护.so文件中的接口函数
3. 可以自我维护
	1. 维护版本号
	2. 知道自己的名称
	3. 维护本模块内部的接口
	4. 可以对模块进行初始化

|       字段       |                          名称                          |
|:----------------:|:------------------------------------------------------:|
|     主版本号     |                                                        |
|     次版本号     |                                                        |
|     模块名称     |                          name                          |
|   入口函数指针   | `int (*handle)(void* <!-- in -->,void *<!-- out -->);` |
| 初始化函数的指针 |                `int (*int)(Module *);`                 |

## 设计入口函数指针原型：
`int (*handle)(void* <!-- in -->,void *<!-- out -->);`

## 设计初始化函数指针原型
`int (*int)(Module *);` 

## 模块管理器设计
1. 载入模块的操作
```C++
int LoadModule(char *path,char *name);
Module* getModule

```

2. 载入模块操作的处理流程
	1. 通过路径找到模块文件
	2. 调用dlopen打开动态库（.so）
	3. 使用动态库
	```C++
	// 
	g++ -c -fPIC hello.cc -o hello.o
	// 生成动态库
	g++ -shared -o obj/libtest.so obj/test.o 
	```

# 下载器设计
下载器模块分为socket功能封装和http解析

## http协议对资源请求的操作
* get指令
get指令向服务器发送的参数或资源描述在URL中体现

* POST质量
向服务器发送的参数或资源描述在URL中体现可以在HTTP头中

http头描述：
首先要有一个HTTP头，下面是一个HTTP内容，HTTP包的内容由HTTP头进行描述，描述的格式：一条数据一行，每条描述
Accept:
Accept_ecoding
Accept_language
Connection:客户端请求连接，有反馈；如果是长连接，反馈结束之后，不会立刻断开；短连接，
Host：服务器IP

## Socket功能框架设计
1. 创建socket
2. 连接远程服务器
3. 发送数据
4. 接受数据
5. 断开连接
把socket句柄注册到epoll处理事件中。（在主流程中）


## http模块
1. 解析头
2. 组装头


## 提取http数据内容（单独一个模块）
设计两个模块：文本处理模块（html格式），二进制处理模块（image）

注意：
需要了解的相关知识：
1. http协议（可以通过查询RFC协议文档了解更多。专门用来解释网络协议的一种）
	* get指令
	* 请求头的结构
	* 反馈头的结构
2. http协议传输文件的模式

# 页面解析器设计
html文档，是一种标记性语言

对页面解析的目的：
得到页面中存在的下级url

url保存在<a>标签的href属性中

可以通过正则表达式提取页面中的URL
注意提取到URL深度

页面解析的处理流程：
1. 得到下载的页面
2. 得到页面对应的URL结构体（用于得到当前页面的深度）
3. 使用正则表达式得到页面中所有的URl列表
4. 处理URL中的相对路径
5. 吧当前页面深度加一，生成并填充URL结构体
6. 把得到的URL列表回写到URL管理器中（生成列表数据，以返回值形式回传给上层代码） 

# 持久化器模块设计
仍然以模块形式生成
分为网页保存模块和图片保存模块

注意：如果涉及到网页编码 需要进行

处理流程
1. 得到页面的数据流或在内存缓冲区的数据
2. 得到当前页面的url描述结构体
3. 生成保存目录（如果已存在如何处理，如何未存在如何处理）
4. 吧文件按照指定的模式写入磁盘系统
5. 向主处理流程发送一个反馈，表示当前页面处理的进度（回写当前页面的处理状态） 

系统的核心代码：
1. 系统主处理框架
2. Epoll框架的调用
3. 插件模块的完整实现
4. Socket功能封装
5. http协议头解析
6. html解析并提取URL列表
7. URL管理器的实现

后续工作：如何进行但愿测试 cunit
把软件做成系统服务，需要shell脚本支持
集成测试


关于项目的实施
1. 关于项目的实施，项目有多少人来做
	根据项目的大小决定

2. 进入项目编码阶段
   仍然是先进行更小的设计，把当前模块的处理流程想清楚
   先完成程序框架

3. 如果在编码中遇到了从来没有用到过的技术该怎么处理？
   应该先写一个独立的验证demo，否则一旦发现bug，对bug的定位和解决非常困难

4. 关于工作的分配是项目管理的流程问题，作为程序员只需要保证自己负责的模块按时提交即可

1. 多路复用
2. 在编写源代码的时候
   1. 注意代码风格
   2. 注释需要注意
   3. 源码的组织结构
      1. 如果软件比较复杂，那么源代码需要按照模块划分下级更小的目录


Libevent
为什么要采用开源库适当的采用一些开源库，对开发效率非常有帮助
1. 开源库一定要成熟
   1. 怎样判断开源库的成熟度？
      口碑，被广泛使用的一般都是成熟的
	  Relese 版本成熟
	  Beta版本测试版，一般不成熟
	  Rc版本稳定性比beta版本高
	  最后一个提交版本，最不稳定的


代码产生bug的原因
1. 代码产生的原因
   1. 低级错误，编译器可以帮助我们检查大部分
   2. 一些编译器检测不到的低级错误，例如
	```C++
	if(val = 1)
	{

	}
	```
   3. 逻辑上的错误
   4. 某些该进行容错的地方没有容错 

使用单元测试工具例如CUNIT

使用CUNIT之前要先有测试用例
根据测试编写测试代码
执行测试用例代码

1. 一般和程序名称相同名字的源码文件为入口，或main.c，或通过查阅说明文件找到入口
2. 找到主处理流程，理解流程，不要过早的在意细节

